{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90615,"databundleVersionId":10570201,"sourceType":"competition"},{"sourceId":10272231,"sourceType":"datasetVersion","datasetId":6355782}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":null,"end_time":null,"environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-22T04:14:18.804062","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"193e635d","cell_type":"markdown","source":"# Fine-tuning\n\n\nğŸ“’Notebook Created by â¤ï¸ [@prasadmahamulkar](https://x.com/prsdm17). Check out the step by step guide [here.](https://medium.com/@prasadmahamulkar/fine-tuning-phi-2-a-step-by-step-guide-e672e7f1d009)\n\nğŸ“„Dataset: [MedQuad-phi2-1k](https://huggingface.co/prsdm/MedQuad-phi2-1k). You can run this notebook in Google Colab using T4 GPU.\n","metadata":{"id":"A_OYiWbnxioB","papermill":{"duration":0.007498,"end_time":"2024-12-22T04:14:21.031899","exception":false,"start_time":"2024-12-22T04:14:21.024401","status":"completed"},"tags":[]}},{"id":"278b85fc","cell_type":"code","source":"# Install and import the necessary libraries\n!pip install torch\n!pip install -q -U accelerate peft bitsandbytes transformers einops\n!pip install trl==0.12.0\n!pip install triton\n!pip install flash-attn","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:58:09.367082Z","iopub.execute_input":"2024-12-22T21:58:09.367420Z","iopub.status.idle":"2024-12-22T21:58:31.813750Z","shell.execute_reply.started":"2024-12-22T21:58:09.367391Z","shell.execute_reply":"2024-12-22T21:58:31.812654Z"},"id":"yQAVFua5xIP0","outputId":"94ca7111-ce7d-4e69-f7d9-1e1e89c9dd94","papermill":{"duration":22.1474,"end_time":"2024-12-22T04:14:43.184836","exception":false,"start_time":"2024-12-22T04:14:21.037436","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/44.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h"]},{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/336.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/374.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/69.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/69.1 MB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/69.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/69.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.6/69.1 MB\u001b[0m \u001b[31m217.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.9/69.1 MB\u001b[0m \u001b[31m213.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.5/69.1 MB\u001b[0m \u001b[31m195.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.4/69.1 MB\u001b[0m \u001b[31m195.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.3/69.1 MB\u001b[0m \u001b[31m199.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.1/69.1 MB\u001b[0m \u001b[31m199.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m59.0/69.1 MB\u001b[0m \u001b[31m198.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m66.0/69.1 MB\u001b[0m \u001b[31m198.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m203.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/10.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/10.1 MB\u001b[0m \u001b[31m221.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m217.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/450.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"]},{"name":"stdout","output_type":"stream","text":["\r","\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m227.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h"]}],"execution_count":1},{"id":"39e4b175","cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom datasets import load_from_disk\nfrom peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\n\nfrom trl import SFTTrainer\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:09.446597Z","iopub.execute_input":"2024-12-22T21:59:09.446839Z","iopub.status.idle":"2024-12-22T21:59:26.049747Z","shell.execute_reply.started":"2024-12-22T21:59:09.446817Z","shell.execute_reply":"2024-12-22T21:59:26.048806Z"},"id":"qktqRakcz7KR","papermill":{"duration":16.587407,"end_time":"2024-12-22T04:15:33.387455","exception":false,"start_time":"2024-12-22T04:15:16.800048","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"1e78f966","cell_type":"markdown","source":"# Preparing Dataset","metadata":{"papermill":{"duration":0.00911,"end_time":"2024-12-22T04:15:33.406741","exception":false,"start_time":"2024-12-22T04:15:33.397631","status":"completed"},"tags":[]}},{"id":"ca658e17","cell_type":"code","source":"# Read train.csv and test.csv\ntrain_df = pd.read_csv(\"/kaggle/input/juridia-hackhaton-fine-tuning-llm-v/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/juridia-hackhaton-fine-tuning-llm-v/test.csv\")\n\n# Display first few rows of the train and test dataframes\nprint(\"Train Data:\")\ndisplay(train_df.head())\nprint(\"Test Data:\")\ndisplay(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:26.055533Z","iopub.execute_input":"2024-12-22T21:59:26.055772Z","iopub.status.idle":"2024-12-22T21:59:26.151913Z","shell.execute_reply.started":"2024-12-22T21:59:26.055752Z","shell.execute_reply":"2024-12-22T21:59:26.151090Z"},"papermill":{"duration":0.091864,"end_time":"2024-12-22T04:15:33.533241","exception":false,"start_time":"2024-12-22T04:15:33.441377","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Train Data:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    file_name                                         long_title        date  \\\n0   8293.html  DÃ©cret nÂ° 2-04-534 du 16 kaada 1425 (29 dÃ©cemb...  2004-12-29   \n1   9003.html  DÃ©cret nÂ° 2-72-513 du 3 rebia I 1393 (7 avril ...  1973-04-07   \n2  11506.html  Dahir nÂ° 1-03-300 du 2 rabii I 1425 (22 avril ...  2004-04-22   \n3  22837.html  ArrÃªtÃ© du ministre de lâ€™Ã©conomie et des financ...  2019-05-30   \n4   7066.html  Dahir nÂ° 1-17-15 du 28 ramadan 1438 (23 juin 2...  2017-06-23   \n\n  doc_type                                    Id  \n0   DÃ©cret  0d5401c3-6d59-4a9f-bbe8-4313b599e94b  \n1   DÃ©cret  fea3e4a6-7535-425f-bdf2-b792f6052cd5  \n2    Dahir  b67a1c82-9fc7-4a4b-8c67-10f45f5b9dd2  \n3   ArrÃªtÃ©  7bace715-97c7-47d5-a321-d17e1bee26a8  \n4    Dahir  5590ac6b-aa88-4b0d-af35-633fbbeb0bbf  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>long_title</th>\n      <th>date</th>\n      <th>doc_type</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8293.html</td>\n      <td>DÃ©cret nÂ° 2-04-534 du 16 kaada 1425 (29 dÃ©cemb...</td>\n      <td>2004-12-29</td>\n      <td>DÃ©cret</td>\n      <td>0d5401c3-6d59-4a9f-bbe8-4313b599e94b</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9003.html</td>\n      <td>DÃ©cret nÂ° 2-72-513 du 3 rebia I 1393 (7 avril ...</td>\n      <td>1973-04-07</td>\n      <td>DÃ©cret</td>\n      <td>fea3e4a6-7535-425f-bdf2-b792f6052cd5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11506.html</td>\n      <td>Dahir nÂ° 1-03-300 du 2 rabii I 1425 (22 avril ...</td>\n      <td>2004-04-22</td>\n      <td>Dahir</td>\n      <td>b67a1c82-9fc7-4a4b-8c67-10f45f5b9dd2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22837.html</td>\n      <td>ArrÃªtÃ© du ministre de lâ€™Ã©conomie et des financ...</td>\n      <td>2019-05-30</td>\n      <td>ArrÃªtÃ©</td>\n      <td>7bace715-97c7-47d5-a321-d17e1bee26a8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7066.html</td>\n      <td>Dahir nÂ° 1-17-15 du 28 ramadan 1438 (23 juin 2...</td>\n      <td>2017-06-23</td>\n      <td>Dahir</td>\n      <td>5590ac6b-aa88-4b0d-af35-633fbbeb0bbf</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Test Data:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Id                                           question\n0   0  Les rÃ©gimes de protection des personnes fragil...\n1   1  Je loue un garage. Quelles rÃ¨gles s'appliquent...\n2   2  Ai-je droit Ã  l'aide juridique (ex pro deo) si...\n3   3  Peut-on saisir ou confisquer la voiture de mes...\n4   4  Quels types de dÃ©cisions relÃ¨vent de l'autorit...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>question</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Les rÃ©gimes de protection des personnes fragil...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Je loue un garage. Quelles rÃ¨gles s'appliquent...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Ai-je droit Ã  l'aide juridique (ex pro deo) si...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Peut-on saisir ou confisquer la voiture de mes...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Quels types de dÃ©cisions relÃ¨vent de l'autorit...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"id":"d7fcfcfa","cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"mouadenna/legal_dataset\")\ndataset=dataset.shuffle(seed=42)","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:27.153742Z","iopub.execute_input":"2024-12-22T21:59:27.153930Z","iopub.status.idle":"2024-12-22T21:59:35.856390Z","shell.execute_reply.started":"2024-12-22T21:59:27.153913Z","shell.execute_reply":"2024-12-22T21:59:35.855715Z"},"papermill":{"duration":6.188878,"end_time":"2024-12-22T04:15:40.106374","exception":false,"start_time":"2024-12-22T04:15:33.917496","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05739a69e5bd4fd9a14f46fb4aa85bbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/106M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbda56322a14c5e8ce95ba0038205cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b263fc73dd644ca39189d809626532c5"}},"metadata":{}}],"execution_count":11},{"id":"755f151c","cell_type":"code","source":"train_test_split = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\ntrain_dataset = train_test_split[\"train\"]\nvalidation_dataset = train_test_split[\"test\"]\n\n\n# Print dataset sizes\nprint(f\"Training set size: {len(train_dataset)}\")\nprint(f\"Validation set size: {len(validation_dataset)}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:35.857182Z","iopub.execute_input":"2024-12-22T21:59:35.857479Z","iopub.status.idle":"2024-12-22T21:59:35.869358Z","shell.execute_reply.started":"2024-12-22T21:59:35.857444Z","shell.execute_reply":"2024-12-22T21:59:35.868677Z"},"papermill":{"duration":0.023904,"end_time":"2024-12-22T04:15:40.142015","exception":false,"start_time":"2024-12-22T04:15:40.118111","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Training set size: 4500\nValidation set size: 500\n","output_type":"stream"}],"execution_count":12},{"id":"5f43e233","cell_type":"code","source":"from huggingface_hub import login","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:35.870177Z","iopub.execute_input":"2024-12-22T21:59:35.870501Z","iopub.status.idle":"2024-12-22T21:59:35.883732Z","shell.execute_reply.started":"2024-12-22T21:59:35.870470Z","shell.execute_reply":"2024-12-22T21:59:35.883072Z"},"papermill":{"duration":0.015882,"end_time":"2024-12-22T04:15:40.168089","exception":false,"start_time":"2024-12-22T04:15:40.152207","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"5408c909","cell_type":"code","source":"login(\"HF_api_key\")","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:35.884454Z","iopub.execute_input":"2024-12-22T21:59:35.884707Z","iopub.status.idle":"2024-12-22T21:59:36.147253Z","shell.execute_reply.started":"2024-12-22T21:59:35.884687Z","shell.execute_reply":"2024-12-22T21:59:36.146383Z"},"papermill":{"duration":0.128056,"end_time":"2024-12-22T04:15:40.306300","exception":false,"start_time":"2024-12-22T04:15:40.178244","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"375ac7d8","cell_type":"code","source":"# Model\n#base_model = \"microsoft/Phi-3-small-8k-instruct\" #\"mistralai/Mistral-Nemo-Base-2407\"\nbase_model= \"microsoft/Phi-3.5-mini-instruct\"\nnew_model = \"phi-3-mini-legal\"\n\n\n# Dataset\n#dataset = load_dataset(\"prsdm/MedQuad-phi2-1k\", split=\"train\")\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True,trust_remote_code=True)\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side=\"left\"","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:36.148120Z","iopub.execute_input":"2024-12-22T21:59:36.148371Z","iopub.status.idle":"2024-12-22T21:59:39.302984Z","shell.execute_reply.started":"2024-12-22T21:59:36.148350Z","shell.execute_reply":"2024-12-22T21:59:39.302018Z"},"id":"XainoHg40CN8","papermill":{"duration":1.290457,"end_time":"2024-12-22T04:15:41.607337","exception":false,"start_time":"2024-12-22T04:15:40.316880","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"812b36e7146445d2b68afbc65e4ad746"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e283b98995047d191b6bdaffcee042f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec723768edc4c8c9599833c193d07a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f2297b9fad4badb421d171f9d7abac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f15d90c09aa416fad5a77864f73a650"}},"metadata":{}}],"execution_count":15},{"id":"5fac7410","cell_type":"code","source":"#dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:39.303980Z","iopub.execute_input":"2024-12-22T21:59:39.304198Z","iopub.status.idle":"2024-12-22T21:59:39.307692Z","shell.execute_reply.started":"2024-12-22T21:59:39.304180Z","shell.execute_reply":"2024-12-22T21:59:39.306780Z"},"papermill":{"duration":0.015547,"end_time":"2024-12-22T04:15:41.634788","exception":false,"start_time":"2024-12-22T04:15:41.619241","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"59ec67d0","cell_type":"code","source":"def print_trainable_parameters(model):\n    total_params = sum(p.numel() for p in model.parameters())\n\n    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f'Total parameters: {total_params}')\n    print(f'Total trainable parameters: {total_trainable_params}')","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:39.308539Z","iopub.execute_input":"2024-12-22T21:59:39.308817Z","iopub.status.idle":"2024-12-22T21:59:39.324916Z","shell.execute_reply.started":"2024-12-22T21:59:39.308789Z","shell.execute_reply":"2024-12-22T21:59:39.324262Z"},"papermill":{"duration":0.016346,"end_time":"2024-12-22T04:15:41.661698","exception":false,"start_time":"2024-12-22T04:15:41.645352","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"80237b37","cell_type":"code","source":"# Quantization configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False,\n)\n\n# Load base moodel\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    low_cpu_mem_usage=True,\n    device_map={\"\": 0},\n    #revision=\"refs/pr/23\" #the main version of Phi-2 doesnâ€™t support gradient checkpointing (while training this model)\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-22T21:59:39.325706Z","iopub.execute_input":"2024-12-22T21:59:39.325887Z","iopub.status.idle":"2024-12-22T22:02:54.050124Z","shell.execute_reply.started":"2024-12-22T21:59:39.325871Z","shell.execute_reply":"2024-12-22T22:02:54.049518Z"},"papermill":{"duration":192.826682,"end_time":"2024-12-22T04:18:54.498954","exception":false,"start_time":"2024-12-22T04:15:41.672272","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ca49db62be4856a07ed8cffb97fc7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2872003944d4a80aa18d23e756208e1"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098b62e1dbde4071b0d859d90ddd3580"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db2f760408f84c808a388972df0a69e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6768a2534494cf698618ce14d57f7b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a810079e3e48c284544bdc4f663848"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8848333c3a44057ad38793faafac249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c249b0ae63424063a8a18629e983a7b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f11852588d324be1994e60f63424aece"}},"metadata":{}}],"execution_count":18},{"id":"e9531e20","cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-12-22T22:02:54.050925Z","iopub.execute_input":"2024-12-22T22:02:54.051147Z","iopub.status.idle":"2024-12-22T22:02:54.056605Z","shell.execute_reply.started":"2024-12-22T22:02:54.051116Z","shell.execute_reply":"2024-12-22T22:02:54.055813Z"},"papermill":{"duration":0.018941,"end_time":"2024-12-22T04:18:54.530045","exception":false,"start_time":"2024-12-22T04:18:54.511104","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)\n","output_type":"stream"}],"execution_count":19},{"id":"789d3d23","cell_type":"code","source":"\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n\n\n# Set training arguments\ntraining_arguments = TrainingArguments(\n    output_dir = \"./results\",\n    num_train_epochs = 2,\n    fp16 = True,\n    bf16 = False,\n    evaluation_strategy=\"steps\",\n    per_device_train_batch_size = 4,\n    per_device_eval_batch_size = 4,\n    gradient_accumulation_steps = 1,\n    gradient_checkpointing = True,\n    max_grad_norm = 0.3,\n    learning_rate = 2e-4,\n    weight_decay = 0.001,\n    optim = \"paged_adamw_32bit\",\n    lr_scheduler_type = \"cosine\",\n    max_steps = -1,\n    warmup_ratio = 0.03,\n    group_by_length = True,\n    save_steps=500,                        \n    logging_steps = 100,\n    \n    report_to=\"none\",  # Disable external logging like wandb\n\n)\n\n# LoRA configuration\npeft_config = LoraConfig(\n    r=8,                   #default=8\n    lora_alpha= 32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules= ['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"] #[\"Wqkv\", \"out_proj\"] #for mistral [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n #[\"Wqkv\", \"fc1\", \"fc2\" ] # [\"Wqkv\", \"out_proj\", \"fc1\", \"fc2\" ]\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length= None,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-22T22:02:54.057441Z","iopub.execute_input":"2024-12-22T22:02:54.057705Z","iopub.status.idle":"2024-12-22T22:04:16.268652Z","shell.execute_reply.started":"2024-12-22T22:02:54.057674Z","shell.execute_reply":"2024-12-22T22:04:16.267760Z"},"id":"ZBtEMcxWyhjM","papermill":{"duration":82.805122,"end_time":"2024-12-22T04:20:17.346962","exception":false,"start_time":"2024-12-22T04:18:54.541840","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84a5ca079eba4cc9a12e29adc9ad2a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"922e00020dd7499c9c0119790a3d8a85"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"id":"73640d56","cell_type":"code","source":"print_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-12-22T22:04:16.269473Z","iopub.execute_input":"2024-12-22T22:04:16.269734Z","iopub.status.idle":"2024-12-22T22:04:16.279132Z","shell.execute_reply.started":"2024-12-22T22:04:16.269712Z","shell.execute_reply":"2024-12-22T22:04:16.278373Z"},"papermill":{"duration":0.02274,"end_time":"2024-12-22T04:20:17.382489","exception":false,"start_time":"2024-12-22T04:20:17.359749","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Total parameters: 2013596672\nTotal trainable parameters: 4456448\n","output_type":"stream"}],"execution_count":21},{"id":"cac4fb6e-c213-43d5-81b5-d7037b15e4e1","cell_type":"code","source":"checkpoint = '/kaggle/input/juridia-result/results/checkpoint-1500'  # Path to your checkpoint\ntrainer.train(resume_from_checkpoint=checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T22:04:50.231983Z","iopub.execute_input":"2024-12-22T22:04:50.232317Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3420: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3083: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint_rng_state = torch.load(rng_file)\n/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1877' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1877/2250 2:09:35 < 2:08:54, 0.05 it/s, Epoch 1.67/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1600</td>\n      <td>0.068400</td>\n      <td>0.072791</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.067500</td>\n      <td>0.072484</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.067100</td>\n      <td>0.072210</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"}],"execution_count":null},{"id":"049fd62f-28e0-494c-97c5-b860ddb06e81","cell_type":"code","source":"p","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-23T01:37:04.128Z"}},"outputs":[],"execution_count":null},{"id":"df556a68","cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.execute_input":"2024-12-22T04:20:17.406669Z","iopub.status.busy":"2024-12-22T04:20:17.406419Z"},"id":"45UAm35t0TKZ","outputId":"e9d60459-2011-4233-e901-222a2d30cc6e","papermill":{"duration":null,"end_time":null,"exception":false,"start_time":"2024-12-22T04:20:17.394232","status":"running"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1954' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1954/2250 11:53:43 < 1:48:13, 0.05 it/s, Epoch 1.74/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.528100</td>\n","      <td>0.096833</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.092900</td>\n","      <td>0.089269</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.085200</td>\n","      <td>0.086117</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.083200</td>\n","      <td>0.083919</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.083900</td>\n","      <td>0.081763</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.082600</td>\n","      <td>0.080222</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.079200</td>\n","      <td>0.078966</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.079600</td>\n","      <td>0.077821</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.080200</td>\n","      <td>0.077311</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.075400</td>\n","      <td>0.076064</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.078100</td>\n","      <td>0.075109</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.073300</td>\n","      <td>0.074574</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.072400</td>\n","      <td>0.074033</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.070000</td>\n","      <td>0.073539</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.071700</td>\n","      <td>0.073133</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.069300</td>\n","      <td>0.072627</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.070300</td>\n","      <td>0.072247</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.068500</td>\n","      <td>0.071984</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.067800</td>\n","      <td>0.071707</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]}],"execution_count":22},{"id":"16f6dcf1","cell_type":"code","source":"# Save trained model\ntrainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.execute_input":"2024-12-22T03:20:48.767568Z","iopub.status.busy":"2024-12-22T03:20:48.767267Z","iopub.status.idle":"2024-12-22T03:20:48.975465Z","shell.execute_reply":"2024-12-22T03:20:48.974403Z","shell.execute_reply.started":"2024-12-22T03:20:48.767541Z"},"id":"MLMlfccP0Ur-","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"907f9c4e","cell_type":"code","source":"# Clear the memory\n#del model, trainer","metadata":{"execution":{"iopub.execute_input":"2024-12-22T03:20:48.977258Z","iopub.status.busy":"2024-12-22T03:20:48.976883Z","iopub.status.idle":"2024-12-22T03:20:48.981217Z","shell.execute_reply":"2024-12-22T03:20:48.980209Z","shell.execute_reply.started":"2024-12-22T03:20:48.977202Z"},"id":"p4ajplZfhIda","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"583d1180","cell_type":"code","source":"# Run text generation pipeline with our model\nlogging.set_verbosity(logging.CRITICAL)\n\n# Assuming the model is already loaded as `model`\n#model = model.to(torch.float32)  # Move the model to float32 (standard floating-point type)\n\nwith torch.no_grad():\n\n    input_text = \"Quels sont les critÃ¨res d'Ã©ligibilitÃ© Ã  la retraite anticipÃ©e ?\"\n    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n    \n    # Ensure input_ids are of the correct type (int64)\n    input_ids = inputs[\"input_ids\"].to(torch.int64)\n    \n    output = model.generate(\n        input_ids, \n        max_length=200, \n        num_return_sequences=1, \n    )\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    print(generated_text)\n","metadata":{"execution":{"iopub.execute_input":"2024-12-22T03:20:48.982381Z","iopub.status.busy":"2024-12-22T03:20:48.982115Z","iopub.status.idle":"2024-12-22T03:21:50.767948Z","shell.execute_reply":"2024-12-22T03:21:50.766970Z","shell.execute_reply.started":"2024-12-22T03:20:48.982358Z"},"id":"nltkxvCS7wl_","outputId":"455b3f8b-b78c-41f7-be03-7e758491b6e5","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"436d2074","cell_type":"code","source":"# Reload model and merge it with LoRA parameters\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    torch_dtype=torch.float16,\n    trust_remote_code=True,\n    cache_dir=\"\",\n    device_map={\"\": 0},\n)\nmodel = PeftModel.from_pretrained(model, new_model)\nmodel = model.merge_and_unload()","metadata":{"execution":{"iopub.execute_input":"2024-12-22T03:21:50.769512Z","iopub.status.busy":"2024-12-22T03:21:50.769123Z","iopub.status.idle":"2024-12-22T03:25:03.115630Z","shell.execute_reply":"2024-12-22T03:25:03.114823Z","shell.execute_reply.started":"2024-12-22T03:21:50.769474Z"},"id":"htHLu5_zyZGW","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"1a3a4b5f","cell_type":"code","source":"# Reload tokenizer to save it\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = 'left'\n","metadata":{"execution":{"iopub.execute_input":"2024-12-22T03:25:03.116823Z","iopub.status.busy":"2024-12-22T03:25:03.116558Z","iopub.status.idle":"2024-12-22T03:25:03.289140Z","shell.execute_reply":"2024-12-22T03:25:03.288071Z","shell.execute_reply.started":"2024-12-22T03:25:03.116798Z"},"id":"UkGyLh1VEN6j","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"5619f702","cell_type":"code","source":"model.push_to_hub(new_model, use_temp_dir=False)\ntokenizer.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.execute_input":"2024-12-22T03:25:03.290571Z","iopub.status.busy":"2024-12-22T03:25:03.290214Z","iopub.status.idle":"2024-12-22T03:27:40.741933Z","shell.execute_reply":"2024-12-22T03:27:40.740945Z","shell.execute_reply.started":"2024-12-22T03:25:03.290536Z"},"id":"4pkR87Cm3RK7","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"c219efb4","cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null}]}