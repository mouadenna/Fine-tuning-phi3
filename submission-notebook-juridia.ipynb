{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:10:53.082244Z",
     "iopub.status.busy": "2024-12-22T16:10:53.081920Z",
     "iopub.status.idle": "2024-12-22T16:11:15.800810Z",
     "shell.execute_reply": "2024-12-22T16:11:15.799756Z",
     "shell.execute_reply.started": "2024-12-22T16:10:53.082215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install and import the necessary librarie\n",
    "!pip install torch\n",
    "!pip install -q -U accelerate peft bitsandbytes transformers einops\n",
    "!pip install language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:11:15.802341Z",
     "iopub.status.busy": "2024-12-22T16:11:15.802078Z",
     "iopub.status.idle": "2024-12-22T16:11:20.491073Z",
     "shell.execute_reply": "2024-12-22T16:11:20.490149Z",
     "shell.execute_reply.started": "2024-12-22T16:11:15.802317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:03:28.663016Z",
     "iopub.status.busy": "2024-12-23T00:03:28.662729Z",
     "iopub.status.idle": "2024-12-23T00:03:28.667854Z",
     "shell.execute_reply": "2024-12-23T00:03:28.666989Z",
     "shell.execute_reply.started": "2024-12-23T00:03:28.662993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:11:20.492812Z",
     "iopub.status.busy": "2024-12-22T16:11:20.492398Z",
     "iopub.status.idle": "2024-12-22T16:11:20.510226Z",
     "shell.execute_reply": "2024-12-22T16:11:20.509613Z",
     "shell.execute_reply.started": "2024-12-22T16:11:20.492788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"/kaggle/input/juridia-hackhaton-fine-tuning-llm-v/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:11:47.612371Z",
     "iopub.status.busy": "2024-12-22T16:11:47.612009Z",
     "iopub.status.idle": "2024-12-22T16:11:51.427652Z",
     "shell.execute_reply": "2024-12-22T16:11:51.426945Z",
     "shell.execute_reply.started": "2024-12-22T16:11:47.612339Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd6ef37f17047d495520fc41545054b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cced430f8844cb49c46cde8f366d14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3c4d34ca7447b999b3a4faf8b816b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad17ff455bd44e2a9e80dd34a48b868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaaaf6d4fa64717ab322b7c894049e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model\n",
    "#base_model = \"microsoft/Phi-3-small-8k-instruct\" #\"mistralai/Mistral-Nemo-Base-2407\"\n",
    "base_model= \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "# Dataset\n",
    "#dataset = load_dataset(\"prsdm/MedQuad-phi2-1k\", split=\"train\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True,trust_remote_code=True)\n",
    "tokenizer.pad_token=tokenizer.eos_token\n",
    "tokenizer.padding_side=\"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-22T16:11:54.830885Z",
     "iopub.status.busy": "2024-12-22T16:11:54.830594Z",
     "iopub.status.idle": "2024-12-22T16:15:15.980941Z",
     "shell.execute_reply": "2024-12-22T16:15:15.980240Z",
     "shell.execute_reply.started": "2024-12-22T16:11:54.830864Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be8b056d02142b1b7e1eaff23fa95b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7143126c9f274b08bc24ddda96f30ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa74587d99a4ba38e8c63d2a2c25e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3829193415294aaaa9b02009e24e6cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d027b33aa2bc4664a3ee978a014bde38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2fc0ed0629461789d1fe73221f89b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118d253473c84d96a2d278fd7f62225b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97eeea8ef26414aa135767094a59cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52060fa6d5942ea837d6bbaee4baf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load base moodel\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map={\"\": 0},\n",
    "    #revision=\"refs/pr/23\" #the main version of Phi-2 doesn’t support gradient checkpointing (while training this model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:21:05.950300Z",
     "iopub.status.busy": "2024-12-22T16:21:05.949959Z",
     "iopub.status.idle": "2024-12-22T16:21:06.567117Z",
     "shell.execute_reply": "2024-12-22T16:21:06.566131Z",
     "shell.execute_reply.started": "2024-12-22T16:21:05.950258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# Load LoRA model\n",
    "peft_model = PeftModel.from_pretrained(model, \"/kaggle/input/juridia-model/results/checkpoint-1500\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T23:53:03.942491Z",
     "iopub.status.busy": "2024-12-22T23:53:03.942139Z",
     "iopub.status.idle": "2024-12-22T23:53:43.475445Z",
     "shell.execute_reply": "2024-12-22T23:53:43.474463Z",
     "shell.execute_reply.started": "2024-12-22T23:53:03.942459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37dbf1048f7400f9b8b84e4e0fc6949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdca1c067bce44ffaec7df079d854f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23968875cc446768b8351e15d1749c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6299c05bd745b9b9978e9874a1b386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d29ca3903b41f682fdb9e2e5f2622f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13993794f6764becb7807e561cb5f032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "sum_tokenizer = AutoTokenizer.from_pretrained(\"plguillou/t5-base-fr-sum-cnndm\")\n",
    "sum_model = AutoModelForSeq2SeqLM.from_pretrained(\"plguillou/t5-base-fr-sum-cnndm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:03:40.104260Z",
     "iopub.status.busy": "2024-12-23T00:03:40.103978Z",
     "iopub.status.idle": "2024-12-23T00:03:40.109499Z",
     "shell.execute_reply": "2024-12-23T00:03:40.108777Z",
     "shell.execute_reply.started": "2024-12-23T00:03:40.104236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(text: str, model=sum_model, tokenizer=sum_tokenizer, device=\"cuda\") -> str:\n",
    "    \"\"\"\n",
    "    Generate summary using the transformer model with improved settings\n",
    "    \"\"\"\n",
    "    # Move the model to the specified device (e.g., 'cuda' or 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    \n",
    "    # Move the inputs to the device\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    # Generate the summary\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=256,  # Increased max length for more complete summary\n",
    "        min_length=120,  # Ensure minimum summary length\n",
    "        num_beams=4,     # Improved beam search\n",
    "        length_penalty=0.1,  # Slightly favor shorter sequences\n",
    "        no_repeat_ngram_size=3,\n",
    "        early_stopping=True,\n",
    "        do_sample=False,     # Deterministic output\n",
    "        temperature=1.0,     # Conservative sampling\n",
    "        top_k=50,           # Limit vocabulary choices\n",
    "        repetition_penalty=1.2  # Avoid repetitive phrases\n",
    "    )\n",
    "\n",
    "    # Move the output back to the CPU before decoding\n",
    "    output = output.to('cpu')\n",
    "    \n",
    "    # Decode the output and return the summary\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:21:14.754317Z",
     "iopub.status.busy": "2024-12-22T16:21:14.753975Z",
     "iopub.status.idle": "2024-12-22T16:21:14.775435Z",
     "shell.execute_reply": "2024-12-22T16:21:14.774589Z",
     "shell.execute_reply.started": "2024-12-22T16:21:14.754276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import language_tool_python\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T16:21:16.559711Z",
     "iopub.status.busy": "2024-12-22T16:21:16.559377Z",
     "iopub.status.idle": "2024-12-22T16:21:30.645213Z",
     "shell.execute_reply": "2024-12-22T16:21:30.644178Z",
     "shell.execute_reply.started": "2024-12-22T16:21:16.559682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:03<00:00, 81.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "def read_gdrive_json(file_id: str):\n",
    "    \"\"\"\n",
    "    Read JSON from Google Drive file.\n",
    "    \"\"\"\n",
    "    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "    try:\n",
    "        response = requests.get(download_url)\n",
    "        response.raise_for_status()\n",
    "        data = json.loads(response.text)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load legal keywords\n",
    "file_id = \"1a9R53Wr8X1oOKDN0iCBT9Yq2A7NETUFE\"\n",
    "legal_keywords = read_gdrive_json(file_id)\n",
    "legal_pattern = re.compile(r\"\\b(?:%s)\\b\" % \"|\".join(map(re.escape, legal_keywords)), re.IGNORECASE)\n",
    "\n",
    "# Cached LanguageTool instance\n",
    "tool = language_tool_python.LanguageTool('fr')  # Adjust to 'ar' for Arabic as needed\n",
    "\n",
    "def calculate_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates Relevance, Completeness, Legal Soundness, Fluency, and Latency for question-answer pairs.\n",
    "    \"\"\"\n",
    "    # Cached TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Pre-fit TF-IDF for all answers and questions\n",
    "    all_texts = df[\"question\"].tolist() + df[\"answer\"].tolist()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    question_matrix = tfidf_matrix[: len(df)]\n",
    "    answer_matrix = tfidf_matrix[len(df) :]\n",
    "\n",
    "    # Legal Soundness Check using precompiled regex\n",
    "    def legal_soundness_check(answer: str) -> float:\n",
    "        return 1.0 if legal_pattern.search(answer) else 0.0\n",
    "\n",
    "    # Fluency Check: Batch process to avoid repeated calls\n",
    "    def fluency_check(answers: list) -> list:\n",
    "        return [max(0.7, 1 - len(tool.check(answer)) / 10) for answer in answers]\n",
    "\n",
    "    # Initialize lists for storing metrics\n",
    "    relevance_scores = cosine_similarity(question_matrix, answer_matrix).diagonal()\n",
    "    completeness_scores = relevance_scores  # Reuse the similarity scores for completeness\n",
    "    legal_soundness_scores = [legal_soundness_check(answer) for answer in df[\"answer\"]]\n",
    "    fluency_scores = fluency_check(df[\"answer\"].tolist())\n",
    "\n",
    "    # Measure latency\n",
    "    latency_times = []\n",
    "    for _, row in df.iterrows():\n",
    "        start_time = time.time()\n",
    "        _ = legal_soundness_check(row[\"answer\"])  # Mimic all calculations\n",
    "        latency_times.append(time.time() - start_time)\n",
    "\n",
    "    # Add calculated metrics to the DataFrame\n",
    "    df[\"relevance\"] = relevance_scores\n",
    "    df[\"completeness\"] = completeness_scores\n",
    "    df[\"legal_soundness\"] = legal_soundness_scores\n",
    "    df[\"fluency\"] = fluency_scores\n",
    "    df[\"latency\"] = latency_times\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_composite_score(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the final weighted composite score based on metrics.\n",
    "    \"\"\"\n",
    "    weights = {\n",
    "        \"relevance\": 0.35,\n",
    "        \"completeness\": 0.2,\n",
    "        \"legal_soundness\": 0.2,\n",
    "        \"fluency\": 0.1,\n",
    "        \"latency\": -0.05\n",
    "    }\n",
    "    weighted_sum = (\n",
    "        weights[\"relevance\"] * df[\"relevance\"].mean() +\n",
    "        weights[\"completeness\"] * df[\"completeness\"].mean() +\n",
    "        weights[\"legal_soundness\"] * df[\"legal_soundness\"].mean() +\n",
    "        weights[\"fluency\"] * df[\"fluency\"].mean() +\n",
    "        weights[\"latency\"] * df[\"latency\"].mean()\n",
    "    )\n",
    "    return round(weighted_sum, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T22:50:44.523032Z",
     "iopub.status.busy": "2024-12-22T22:50:44.522718Z",
     "iopub.status.idle": "2024-12-22T22:50:44.528068Z",
     "shell.execute_reply": "2024-12-22T22:50:44.527249Z",
     "shell.execute_reply.started": "2024-12-22T22:50:44.523008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def prompt_template(question):\n",
    "    return f\"\"\"\n",
    "    ### Instructions:\n",
    "    Provide a concise, legally sound, complete, and relevant answer to the question below.\n",
    "    Keep your response brief while ensuring legal validity and clarity.\n",
    "\n",
    "    ### Question:\n",
    "    {question}\n",
    "\n",
    "    ### Answer:\n",
    "    \"\"\"\n",
    "\n",
    "test_df[\"prompt\"] = test_df[\"question\"].apply(prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:45:04.142056Z",
     "iopub.status.busy": "2024-12-23T00:45:04.141700Z",
     "iopub.status.idle": "2024-12-23T00:45:04.148639Z",
     "shell.execute_reply": "2024-12-23T00:45:04.147830Z",
     "shell.execute_reply.started": "2024-12-23T00:45:04.142023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Model inference function with batching\n",
    "def generate_answers(df: pd.DataFrame, model, tokenizer, batch_size: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate answers for the questions in the dataframe using the language model, processing in batches.\n",
    "    \"\"\"\n",
    "    generated_answers = []\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(df), batch_size)):\n",
    "            batch_questions = df[\"prompt\"].iloc[i:i + batch_size].tolist()\n",
    "            inputs = tokenizer(batch_questions, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            input_ids = inputs[\"input_ids\"]\n",
    "            attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "            output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                min_length=40,\n",
    "                max_new_tokens =200,\n",
    "                num_return_sequences=1,\n",
    "                temperature=0.75,\n",
    "                #repetition_penalty=11.0,\n",
    "                early_stopping=True,\n",
    "                #do_sample=False,\n",
    "                #num_beams=2,\n",
    "                #length_penalty=-10,\n",
    "                #use_cache=True\n",
    "            )\n",
    "\n",
    "            # Remove the input tokens from the output tokens\n",
    "            batch_generated_texts = []\n",
    "            for j, generated_seq in enumerate(output):\n",
    "                input_length = input_ids[j].shape[0]\n",
    "                generated_text = tokenizer.decode(generated_seq[input_length:], skip_special_tokens=True)\n",
    "                batch_generated_texts.append(generated_text)\n",
    "\n",
    "            generated_answers.extend(batch_generated_texts)\n",
    "\n",
    "    df[\"answer\"] = generated_answers\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:45:08.831661Z",
     "iopub.status.busy": "2024-12-23T00:45:08.831235Z",
     "iopub.status.idle": "2024-12-23T01:41:08.731236Z",
     "shell.execute_reply": "2024-12-23T01:41:08.730433Z",
     "shell.execute_reply.started": "2024-12-23T00:45:08.831613Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/220 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.75` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 220/220 [55:59<00:00, 15.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate answers for test_df\n",
    "new_test_df = generate_answers(test_df, peft_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-23T02:20:50.729Z",
     "iopub.execute_input": "2024-12-23T01:41:08.732778Z",
     "iopub.status.busy": "2024-12-23T01:41:08.732544Z",
     "iopub.status.idle": "2024-12-23T01:41:08.736248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_test_df['answer'] = new_test_df['answer'].progress_apply(lambda x: generate_summary(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-23T02:20:50.729Z",
     "iopub.execute_input": "2024-12-23T01:41:08.743186Z",
     "iopub.status.busy": "2024-12-23T01:41:08.742928Z",
     "iopub.status.idle": "2024-12-23T01:41:08.761355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>relevance</th>\n",
       "      <th>completeness</th>\n",
       "      <th>legal_soundness</th>\n",
       "      <th>fluency</th>\n",
       "      <th>latency</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Les régimes de protection des personnes fragil...</td>\n",
       "      <td>Les régimes de protection des personnes fragil...</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Je loue un garage. Quelles règles s'appliquent...</td>\n",
       "      <td>1. Le bail doit être écrit et signé par les de...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ai-je droit à l'aide juridique (ex pro deo) si...</td>\n",
       "      <td>Être mineur ne donne pas automatiquement droit...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Peut-on saisir ou confisquer la voiture de mes...</td>\n",
       "      <td>Être impliqué dans le trafic de drogue peut en...</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Quels types de décisions relèvent de l'autorit...</td>\n",
       "      <td>1. Décision sur l'éducation et la formation de...</td>\n",
       "      <td>0.032606</td>\n",
       "      <td>0.032606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>215</td>\n",
       "      <td>Je pense que mon logement est insalubre. Je m'...</td>\n",
       "      <td>1. Rassemblez des preuves de l'insalubrité, te...</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>Je suis convoqué en justice. Comment vais-je r...</td>\n",
       "      <td>La décision de justice sera délivrée par le ju...</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>Je divorce. Je divorce par consentement mutuel...</td>\n",
       "      <td>Le divorce par consentement mutuel est un proc...</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>Je divorce. Je divorce pour cause de désunion ...</td>\n",
       "      <td>1. Désaccord irréductible sur les valeurs fond...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>Je m'assure que le propriétaire a obtenu un pe...</td>\n",
       "      <td>\\n    En Wallonie, un permis de location est n...</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>\\n    ### Instructions:\\n    Provide a concise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                           question  \\\n",
       "0      0  Les régimes de protection des personnes fragil...   \n",
       "1      1  Je loue un garage. Quelles règles s'appliquent...   \n",
       "2      2  Ai-je droit à l'aide juridique (ex pro deo) si...   \n",
       "3      3  Peut-on saisir ou confisquer la voiture de mes...   \n",
       "4      4  Quels types de décisions relèvent de l'autorit...   \n",
       "..   ...                                                ...   \n",
       "215  215  Je pense que mon logement est insalubre. Je m'...   \n",
       "216  216  Je suis convoqué en justice. Comment vais-je r...   \n",
       "217  217  Je divorce. Je divorce par consentement mutuel...   \n",
       "218  218  Je divorce. Je divorce pour cause de désunion ...   \n",
       "219  219  Je m'assure que le propriétaire a obtenu un pe...   \n",
       "\n",
       "                                                answer  relevance  \\\n",
       "0    Les régimes de protection des personnes fragil...   0.009999   \n",
       "1    1. Le bail doit être écrit et signé par les de...   0.000000   \n",
       "2    Être mineur ne donne pas automatiquement droit...   0.000000   \n",
       "3    Être impliqué dans le trafic de drogue peut en...   0.007612   \n",
       "4    1. Décision sur l'éducation et la formation de...   0.032606   \n",
       "..                                                 ...        ...   \n",
       "215  1. Rassemblez des preuves de l'insalubrité, te...   0.013408   \n",
       "216  La décision de justice sera délivrée par le ju...   0.014567   \n",
       "217  Le divorce par consentement mutuel est un proc...   0.008392   \n",
       "218  1. Désaccord irréductible sur les valeurs fond...   0.000000   \n",
       "219  \\n    En Wallonie, un permis de location est n...   0.022755   \n",
       "\n",
       "     completeness  legal_soundness  fluency   latency  \\\n",
       "0        0.009999              1.0      0.7  0.000295   \n",
       "1        0.000000              0.0      0.7  0.000998   \n",
       "2        0.000000              1.0      0.7  0.000929   \n",
       "3        0.007612              1.0      0.7  0.000158   \n",
       "4        0.032606              1.0      0.7  0.000887   \n",
       "..            ...              ...      ...       ...   \n",
       "215      0.013408              1.0      0.7  0.000349   \n",
       "216      0.014567              1.0      0.7  0.000018   \n",
       "217      0.008392              1.0      0.7  0.000595   \n",
       "218      0.000000              1.0      0.7  0.000607   \n",
       "219      0.022755              1.0      0.7  0.000174   \n",
       "\n",
       "                                                prompt  \n",
       "0    \\n    ### Instructions:\\n    Provide a concise...  \n",
       "1    \\n    ### Instructions:\\n    Provide a concise...  \n",
       "2    \\n    ### Instructions:\\n    Provide a concise...  \n",
       "3    \\n    ### Instructions:\\n    Provide a concise...  \n",
       "4    \\n    ### Instructions:\\n    Provide a concise...  \n",
       "..                                                 ...  \n",
       "215  \\n    ### Instructions:\\n    Provide a concise...  \n",
       "216  \\n    ### Instructions:\\n    Provide a concise...  \n",
       "217  \\n    ### Instructions:\\n    Provide a concise...  \n",
       "218  \\n    ### Instructions:\\n    Provide a concise...  \n",
       "219  \\n    ### Instructions:\\n    Provide a concise...  \n",
       "\n",
       "[220 rows x 9 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on Answer Structuring with Different Templates (Systematic Variation Prompts)\n",
    "\n",
    "In this experiment, we explore the effect of using different response templates on providing answers to legal questions.\n",
    "\n",
    "1. **Without Prompt Template**  \n",
    "   In this case, the answers are provided without any specific template or guidelines. The goal is to see how answers are formulated based on the question.\n",
    "\n",
    "\n",
    "2. **With Prompt Template (Question-Answer)**  \n",
    "   This template focuses on formatting the answer in a simple, question-answer structure without applying additional formatting rules or legal constraints. This allows us to observe how the model performs when it's asked to follow a basic template.\n",
    "\n",
    "\n",
    "3. **With Prompt Template (Legally Sound, Complete, Relevant, and Concise Answers)**  \n",
    "   In this template, the answers are constrained to be legally valid, fluent, and concise. This version is aimed at producing high-quality, formal responses suitable for legal contexts. We test the model’s ability to filter unnecessary information while maintaining the completeness and legality of the answer.\n",
    "\n",
    "- English\n",
    "#Respond only with legally sound, complete, relevant, and concise answers, <br>\n",
    "#ensuring legal validity, fluency, and completeness.\n",
    "\n",
    "\n",
    "- French\n",
    "#Répondez uniquement par des réponses juridiquement solides, complètes,<br>\n",
    "#pertinentes et concises, en garantissant la validité juridique, la fluidité et l'exhaustivité.\n",
    "\n",
    "However the french one yield better result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:12:54.343772Z",
     "iopub.status.busy": "2024-12-23T00:12:54.343433Z",
     "iopub.status.idle": "2024-12-23T00:12:54.349568Z",
     "shell.execute_reply": "2024-12-23T00:12:54.348708Z",
     "shell.execute_reply.started": "2024-12-23T00:12:54.343743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Peut-on saisir ou confisquer la voiture de mes parents que j’utilise pour un trafic de cannabis ?',\n",
       " \"Le trafic de drogue peut entraîner des conséquences légales, y compris la confiscation de véhicules utilisés dans le crime. La législation spécifique et les procédures varient selon la juridiction. Il est conseillé de consulter un avocat spécialisé en droit pénal pour comprendre les conséquences potentielles à prendre en considération dans le cas d'un impliqué dans le trafic de stupéfiants. Il s'agit notamment de la saisie de voitures.\")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with prommpt template\n",
    "\n",
    "#Répondez uniquement par des réponses juridiquement solides, complètes,\n",
    "#pertinentes et concises, en garantissant la validité juridique, la fluidité et l'exhaustivité.\n",
    "\n",
    "#this yield the best result\n",
    "idx=3\n",
    "new_test_df.iloc[idx][\"question\"],new_test_df.iloc[idx][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:13:00.763242Z",
     "iopub.status.busy": "2024-12-23T00:13:00.762972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_with_metrics = calculate_metrics(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T00:31:21.210831Z",
     "iopub.status.busy": "2024-12-23T00:31:21.210455Z",
     "iopub.status.idle": "2024-12-23T00:31:21.225371Z",
     "shell.execute_reply": "2024-12-23T00:31:21.224482Z",
     "shell.execute_reply.started": "2024-12-23T00:31:21.210802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>relevance</th>\n",
       "      <th>completeness</th>\n",
       "      <th>legal_soundness</th>\n",
       "      <th>fluency</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Les régimes de protection des personnes fragil...</td>\n",
       "      <td>Les régimes de protection des personnes fragil...</td>\n",
       "      <td>0.414866</td>\n",
       "      <td>0.414866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Je loue un garage. Quelles règles s'appliquent...</td>\n",
       "      <td>Le bail doit être écrit et signé par les deux ...</td>\n",
       "      <td>0.330525</td>\n",
       "      <td>0.330525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ai-je droit à l'aide juridique (ex pro deo) si...</td>\n",
       "      <td>Le droit à une telle aide dépend de la législa...</td>\n",
       "      <td>0.248854</td>\n",
       "      <td>0.248854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Peut-on saisir ou confisquer la voiture de mes...</td>\n",
       "      <td>Le trafic de drogue peut entraîner des conséqu...</td>\n",
       "      <td>0.194504</td>\n",
       "      <td>0.194504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Quels types de décisions relèvent de l'autorit...</td>\n",
       "      <td>Les décisions sur les dépenses liées aux enfan...</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>215</td>\n",
       "      <td>Je pense que mon logement est insalubre. Je m'...</td>\n",
       "      <td>Rassemblez des preuves de l'insalubrité, telle...</td>\n",
       "      <td>0.288132</td>\n",
       "      <td>0.288132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>Je suis convoqué en justice. Comment vais-je r...</td>\n",
       "      <td>La décision de justice sera délivrée par le ju...</td>\n",
       "      <td>0.096007</td>\n",
       "      <td>0.096007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>Je divorce. Je divorce par consentement mutuel...</td>\n",
       "      <td>Le divorce par consentement mutuel est un proc...</td>\n",
       "      <td>0.516586</td>\n",
       "      <td>0.516586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>Je divorce. Je divorce pour cause de désunion ...</td>\n",
       "      <td>L'abus physique, émotionnel ou psychologique. ...</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>Je m'assure que le propriétaire a obtenu un pe...</td>\n",
       "      <td>Il est important de consulter les règlements l...</td>\n",
       "      <td>0.240645</td>\n",
       "      <td>0.240645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                           question  \\\n",
       "0      0  Les régimes de protection des personnes fragil...   \n",
       "1      1  Je loue un garage. Quelles règles s'appliquent...   \n",
       "2      2  Ai-je droit à l'aide juridique (ex pro deo) si...   \n",
       "3      3  Peut-on saisir ou confisquer la voiture de mes...   \n",
       "4      4  Quels types de décisions relèvent de l'autorit...   \n",
       "..   ...                                                ...   \n",
       "215  215  Je pense que mon logement est insalubre. Je m'...   \n",
       "216  216  Je suis convoqué en justice. Comment vais-je r...   \n",
       "217  217  Je divorce. Je divorce par consentement mutuel...   \n",
       "218  218  Je divorce. Je divorce pour cause de désunion ...   \n",
       "219  219  Je m'assure que le propriétaire a obtenu un pe...   \n",
       "\n",
       "                                                answer  relevance  \\\n",
       "0    Les régimes de protection des personnes fragil...   0.414866   \n",
       "1    Le bail doit être écrit et signé par les deux ...   0.330525   \n",
       "2    Le droit à une telle aide dépend de la législa...   0.248854   \n",
       "3    Le trafic de drogue peut entraîner des conséqu...   0.194504   \n",
       "4    Les décisions sur les dépenses liées aux enfan...   0.088229   \n",
       "..                                                 ...        ...   \n",
       "215  Rassemblez des preuves de l'insalubrité, telle...   0.288132   \n",
       "216  La décision de justice sera délivrée par le ju...   0.096007   \n",
       "217  Le divorce par consentement mutuel est un proc...   0.516586   \n",
       "218  L'abus physique, émotionnel ou psychologique. ...   0.018821   \n",
       "219  Il est important de consulter les règlements l...   0.240645   \n",
       "\n",
       "     completeness  legal_soundness  fluency   latency  \n",
       "0        0.414866              0.0      1.0  0.000826  \n",
       "1        0.330525              1.0      1.0  0.000021  \n",
       "2        0.248854              0.0      0.9  0.000597  \n",
       "3        0.194504              1.0      1.0  0.000111  \n",
       "4        0.088229              0.0      1.0  0.000625  \n",
       "..            ...              ...      ...       ...  \n",
       "215      0.288132              1.0      0.8  0.000173  \n",
       "216      0.096007              1.0      0.7  0.000074  \n",
       "217      0.516586              1.0      0.9  0.000563  \n",
       "218      0.018821              0.0      1.0  0.000516  \n",
       "219      0.240645              1.0      0.8  0.000555  \n",
       "\n",
       "[220 rows x 8 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_with_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T22:26:12.887196Z",
     "iopub.status.busy": "2024-12-22T22:26:12.886979Z",
     "iopub.status.idle": "2024-12-22T22:26:12.898324Z",
     "shell.execute_reply": "2024-12-22T22:26:12.897457Z",
     "shell.execute_reply.started": "2024-12-22T22:26:12.887177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"Id\": [0],  # Single identifier for the row\n",
    "    \"relevance\": [test_df_with_metrics[\"relevance\"].mean()],\n",
    "    \"completeness\": [test_df_with_metrics[\"completeness\"].mean()],\n",
    "    \"legal_soundness\": [test_df_with_metrics[\"legal_soundness\"].mean()],\n",
    "    \"fluency\": [test_df_with_metrics[\"fluency\"].mean()],\n",
    "    \"latency\": [test_df_with_metrics[\"latency\"].mean()],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T22:26:12.899449Z",
     "iopub.status.busy": "2024-12-22T22:26:12.899173Z",
     "iopub.status.idle": "2024-12-22T22:26:12.910685Z",
     "shell.execute_reply": "2024-12-22T22:26:12.910024Z",
     "shell.execute_reply.started": "2024-12-22T22:26:12.899414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv(\"submission3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the composite score for test_df\n",
    "composite_score = calculate_composite_score(test_df_with_metrics)\n",
    "print(\"\\nComposite Score for test_df:\")\n",
    "print(composite_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10570201,
     "sourceId": 90615,
     "sourceType": "competition"
    },
    {
     "datasetId": 6355027,
     "sourceId": 10271216,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
